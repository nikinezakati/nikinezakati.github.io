---
title: ""
date: 2025-11-12
slug: multimodal
share: false
commentable: false
editable: false
---

<div class="project-cards">
<div class="project-card">
  <h3>Robust Multimodal Learning</h3>
    <p>
      Multimodal systems often struggle when one or more input sources are missing, corrupted, or imbalanced. My work develops learning strategies that preserve performance under these real-world conditions by enabling models to reason effectively with incomplete information. This includes designing projection-based methods that learn to estimate missing modality representations directly from the available ones and training unified models that handle all missing-modality configurations without the need for modality-specific retraining or complex adaptation procedures. I also explore efficient fine-tuning techniques, such as LoRA-based unimodal adaptation, to reduce computational overhead while maintaining strong performance across diverse modalities and tasks. These efforts benefit from my background in NLP, which strengthens my understanding of cross-modal interactions and how language models can support robust reasoning when some modalities are absent.
    </p>
</div>
</div>


<style>
.project-cards {
  display: flex;
  flex-direction: column;
  gap: 1.25rem;
  margin-top: 1.5rem;
}
.project-card {
  border: 1px solid #97c2e6ff;
  border-radius: 10px;
  padding: 0.9rem 1.4rem;
  box-shadow: 0 6px 18px rgba(0, 0, 0, 0.08);
  background: #97c2e6ff;
  width: 100%;
}
.project-card h3 {
  margin: 0 0 0.75rem 0;
}
.project-card p {
  margin: 0;
  text-align: justify;
}
</style>
